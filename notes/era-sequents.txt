// era-sequents.txt
// Copyright 2013 Ross Angle. Released under the MIT License.


// Here's a map of the dependencies among the twelve language
// fragments, with "[ ]" showing which ones we haven't implemented:
//
// Local collaboration
//   Deductive
//   Action
// Local collaborative value-level definition
//   Local collaboration
//     ...
//   Knowledge query
//     Action
// [ ] Local collaborative phantom type
//   Local collaboration
//     ...
// [ ] Local collaborative extensible sum
//   Local collaboration
//     ...
//   [ ] Observational subtyping
//     Deductive
// Kitchen sink "un"-type
//   Imperative partial computation
//     Partiality monad
//       Deductive
//   Statically generated dynamic token
//     Deductive
//     Action
//
// At this point, we're not aiming to implement the other three
// fragments yet. We'll use these features with a surface syntax layer
// to make a relatively unambitious Scheme-like programming language.

// This originally used a much less lispy syntax. The original version
// is still available as a GitHub Gist, linked to by a blog post.
//
// This Gist: https://gist.github.com/4559120
//
// The blog post:
// http://rocketnia.wordpress.com/2013/01/29/an-extensible-type-system-for-meaning-preserving-modularity/
//
// For this version, we're taking the original grammar design and
// filling it out with lots of extra annotations to make the checker
// easy to write. For one thing, every function call expression must
// come with a full description of the function type it's calling. For
// another, when the original inference rules would have allowed
// certain expressions on the grounds that an observed action
// ambiently enabled them, for now we instead force those dependencies
// to the top level. For instance, we use (withsecret ...) and
// (witheach ...).
//
// That original Gist didn't tackle the problem of what to do if an
// an author publishes two definitions with the same key and the same
// same type. We don't prevent that scenario from happening, but we do
// do settle on a consistent interpretation. Instead of saying "the
// definition," we say "each definition."


// Start of a bibliography:
//
// http://www.cs.nott.ac.uk/~txa/publ/obseqnow.pdf
// http://twelf.org/wiki/Canonical_form
// http://arxiv.org/pdf/1201.5240v2.pdf
// http://www.mpi-sws.org/~dreyer/papers/proposal/proposal.ps
// http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.106.7073
// http://homotopytypetheory.org/2011/04/23/running-circles-around-in-your-proof-assistant/
// http://www.scala-lang.org/docu/files/IC_TECH_REPORT_200433.pdf
// http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.26.957
// http://golem.ph.utexas.edu/category/2012/11/freedom_from_logic.html
// http://www.cs.nott.ac.uk/~txa/publ/pisigma-new.pdf
// http://www.daimi.au.dk/~eernst/tool07/papers/maspeghi04-ernst.pdf



// ===== Deductive fragment ==========================================
//
// Underlies all other fragments, except maybe the action fragment.


// == Grammar ==

// NOTE: Where we would say (a) |- (b) --- (c) |- (d), a more explicit
// sequent calculus might say (Gamma; a) |- (b) --- (Gamma; c) |- (d).
// Our inference rules always universally quanify over a context of
// preexisting facts, and their entailments always assume those facts.

// NOTE: (by Ross Angle) Currently I'm bending over backwards to avoid
// defining a term "(type)" that represents the type of a type. It's
// my way to avoid the intuition that the logic should support
// (describes (type) (type)), aka "Type : Type", and become
// inconsistent. Besides, I'm not yet convinced that "here's a type"
// is the most interesting theorem a type object demonstrates, nor
// that general "for all types..." quantification is a particularly
// valuable abstraction tool (even though we use it here).

// ift: if type
// tfa: total for-all
// tfn: total function
// tcall: total call
// ttfa: total type for-all
// ttfn: total type function (a function that takes types to values)
// ttcall: total type call
// sfa: sigma for-all
// sfn: sigma function (i.e. a dependent pair)
// fst: first (of an sfn)
// snd: second (of an sfn)

// A root node:
INFERENCE_RULES ::= Rule*

Rule ::=| Entailment* "---" Entailment*  // deduction
Rule ::=| Term "~~>" Term  // beta reduction
Entailment ::=| Fact*"," "|-" Fact*","
Fact ::=| "(" Fact ")"
Fact ::=| UserVar "@" UserKnowledge
UserKnowledge ::=| "(" "istype" Term ")"
UserKnowledge ::=| "(" "describes" Term Term ")"
Arg ::= "^" TermVar
Term ::=| TermVar
Term ::=| "(" "bottom" ")"
Term ::=| "(" "absurd" Term Term ")"
// TODO: See if we should provide a way to make (subval ...) proofs
// equating any two units.
Term ::=| "(" "unittype" ")"
Term ::=| "(" "unit" ")"
Term ::=| "(" "bool" ")"
Term ::=| "(" "true" ")"
Term ::=| "(" "false" ")"
Term ::=| "(" "ift" Term Term Term ")"
// TODO: See if we should make this provide (subval ...) proofs in
// each of its branches.
Term ::=| "(" "if" Term Arg Term Term Term ")"
// Total functions from value to value
Term ::=| "(" "tfa" Arg Term Term ")"
Term ::=| "(" "tfn" Arg Term Term ")"
Term ::=| "(" "tcall" Arg Term Term Term Term ")"
// Total functions from type to value
Term ::=| "(" "ttfa" Arg Term ")"
Term ::=| "(" "ttfn" Arg Term ")"
Term ::=| "(" "ttcall" Arg Term Term Term ")"
// Strong Sigma type
Term ::=| "(" "sfa" Arg Term Term ")"
Term ::=| "(" "sfn" Arg Term Term Term ")"
Term ::=| "(" "fst" Arg Term Term Term ")"
Term ::=| "(" "snd" Arg Term Term Term ")"
UserVar ::= Word | "me" | "you"
TermVar ::= Word
// NOTE: This is the grammar of nonempty sequences of case-insensitive
// ASCII letters. When another grammar is specified as an alternation
// of this one and several particular examples, those examples are the
// only instances we actually use for that grammar in this document.
Word ::= ...

// Only for inference rules, not code:
Term ::=| TermVar ("[" Term "]")+

// Shorthands:
Entailment ::=| Fact  // short for |- (fact)
Fact ::=| UserKnowledge  // short for "me @ userKnowledge"
Term ::=| "let" (Term "=" Term)* "in" Term
  // introduces other abbreviations
Term ::=| "(" "either" Term Term ")"
  // short for (sfa ^tag (bool) (ift tag term1 term2))
Term ::=| "(" "maybe" Term ")"  // short for (either term (unittype))


// == Inference rules ==

// TODO: Prove a cut elimination theorem or something for all of this.

// Introduce (bottom), (unittype), (unit), (bool), (true), and
// (false).
|-  // Tautology
---
(istype (bottom))
(istype (unittype))
(describes (unittype) (unit))
(istype (bool))
(describes (bool) (true))
(describes (bool) (false))

// Eliminate (bottom) and introduce (absurd ...).
(describes (bottom) contradiction)
(istype mightAsWellType)
---
(describes mightAsWellType (absurd contradiction mightAsWellType))

// Eliminate (bool) and introduce (if ...) and (ift ...).
(describes (bool) condition)
(describes (bool) c) |- (istype resultType[ c ])
(describes resultType[ (true) ] then)
(describes resultType[ (false) ] else)
---
(describes (ift condition thenType elseType)
  (if condition ^c resultType[ c ] then else))

// Introduce (tfn ...) and (tfa ...).
(istype xType)
(describes xType x)
  |- (istype yType[ x ]), (describes yType[ x ] y[ x ])
---
(istype (tfa ^x xType yType[ x ]))
(describes (tfa ^x xType yType[ x ]) (tfn x ^xType y[ x ]))

// Eliminate (tfa ...) and introduce (tcall ...).
(describes (tfa ^x xType yType[ x ]) f)
(describes xType xExample)
---
(describes yType[ xExample ] (tcall ^x xType yType[ x ] f xExample))

// Eliminate (tfn ...) and (tcall ...).
(tcall ^x xType yType[ x ] (tfn ^x xType y[ x ]) xExample)
~~>
y[ xExample ]

// Introduce (ttfn ...) and (ttfa ...).
(istype x) |- (istype yType[ x ]), (describes yType[ x ] y[ x ])
---
(istype (ttfa ^x yType[ x ]))
(describes (ttfa ^x yType[ x ]) (ttfn ^x y[ x ]))

// Eliminate (ttfa ...) and introduce (ttcall ...).
(describes (ttfa ^x yType[ x ]))
(istype xExample)
---
(describes yType[ xExample ] (ttcall ^x yType[ x ] f xExample))

// Eliminate (ift ...) and (true).
(ift (true) then else)
~~>
then

// Eliminate (ift ...) and (false).
(ift (false) then else)
~~>
else

// Eliminate (if ...) and (true).
(if (true) ^c resultType[ c ] then else)
~~>
then

// Eliminate (if ...) and (false).
(if (false) ^c resultType[ c ] then else)
~~>
else

// Eliminate (ttfn ...) and (ttcall ...).
(ttcall ^x yType[ x ] (ttfn ^x y[ x ]) xExample)
~~>
y[ xExample ]

// Introduce (sfa ...) and (sfn ...).
(istype x1) |- (istype yType[ x1 ])
(describes xType xVal)
(describes yType[ xVal ] y[ xVal ])
---
(istype (sfa ^x xType yType[ x ]))
(describes (sfa ^x xType yType[ x ]) (sfn ^x xType xVal y[ x ]))

// Eliminate (sfa ...).
(describes (sfa ^x xType yType[ x ]) s)
---
(describes xType (fst ^x xType yType[ ^x ] s))
(describes yType[ (fst ^x xType yType[ ^x ] s) ]
  (snd ^x xType yType[ ^x ] s))

// Eliminate (sfn ...) and (fst ...).
(fst ^x xType yType[ x ] (sfn ^x xType xVal y[ x ]))
~~>
xVal

// Eliminate (sfn ...) and (snd ...).
(snd ^x xType yType[ x ] (sfn ^x xType xVal y[ x ]))
~~>
y[ xVal ]



// ===== Observational subtyping fragment ============================
//
// Depends on the deductive fragment.

// This is essentially the equality constructed in "Observational
// Equality, Now!" However, we don't necessarily intend to treat it as
// a symmetrical judgment.


// == Grammar ==

Term ::=| "(" "subtype" Term Term ")"
Term ::=| "(" "subval" Term Term Term Term ")"
  // value equivalence across a subtype coercion
Term ::=| "(" "coerce" Term Term Term Term ")"
Term ::=| "(" "coherent" Term Term ")"
// NOTE: We need (typerefl ...) and (valrefl ...) in order to prove
// self-equality of encapsulated or otherwise non-deductive types and
// values.
// TODO: Figure out what else we need. Maybe we need to know that
// equal values passed to equal functions yield equal results.
Term ::=| "(" "typerefl" Term ")"
Term ::=| "(" "valrefl" Term Term ")"


// == Inference rules ==

(istype a)
(istype b)
---
(istype (subtype a b))

(describes aType a)
(describes bType b)
---
(istype (subval aType a bType b))

(describes (subtype a b) pf)
(describes a x)
---
(describes b (coerce a b pf x))
(describes (subval a x b (coerce a b pf x)) (coherent pf x))

(istype a)
---
(describes (subtype a a) (typerefl a))

(describes a x)
---
(describes (subval a x a x) (valrefl a x))

(coerce (bottom) (bottom) pf orig)
~~>
orig

(subtype (bottom) (bottom))
~~>
(unittype)

(subval (bottom) a (bottom) b)
~~>
(unittype)

(coerce (unittype) (unittype) pf orig)
~~>
orig

(subtype (unittype) (unittype))
~~>
(unittype)

(subval (unittype) a (unittype) b)
~~>
(unittype)

(coerce (bool) (bool) pf orig)
~~>
orig

(subtype (bool) (bool))
~~>
(unittype)

(subval (bool) a (bool) b)
~~>
(ift a
  (ift b (unittype) (bottom))
  (ift b (bottom) (unittype)))

(coerce (tfa ^x ai ao[ x ]) (tfa ^x bi bo[ x ]) pf orig)
~~>
let
  convertypftype4[ bx ][ ax ] = (subtype ao[ ax ] bo[ bx ])
  convertypftype3[ bx ][ ax ] =
    (tfa ^_ (subval bi bx ai ax) convertypftype4[ bx ][ ax ])
  convertypftype2[ bx ] = (tfa ^ax ai convertypftype3[ bx ][ ax ])
  convertypftype1 = (tfa ^bx bi convertypftype2[ bx ])
  convertxpf = (fst ^_ (subtype bi ai) convertypftype1 pf)
  convertx[ bx ] = (coerce bi ai convertxpf bx)
  convertypf[ bx ][ ax ][ pf ] =
    (tcall ^_ (subval bi bx ai ax) convertypftype4[ bx ][ ax ]
      (tcall ^ax2 ai convertypftype3[ bx ][ ax2 ]
        (tcall ^bx2 bi convertypftype2[ bx2 ][ ax2 ]
          (snd ^_ (subtype bi ai) convertypftype1 pf)
          bx)
        ax)
      pf)
in
(tfn ^bx bi
  (coerce ao[ convertx[ bx ] ] bo[ bx ]
    convertypf[ bx ][ convertx[ bx ] ][ (coherent convertxpf bx) ]
    (tcall ^ax ai ao[ ax ] orig convertx[ bx ])))

(subtype (tfa ^x ai ao[ x ]) (tfa ^x bi bo[ x ]))
~~>
(sfa ^_ (subtype bi ai)
  (tfa ^bx bi
    (tfa ^ax ai
      (tfa ^_ (subval bi bx ai ax) (subtype ao[ ax ] bo[ bx ])))))

(subval (tfa ^x ai ao[ x ]) a (tfa ^x bi bo[ x ]) b)
~~>
(tfa ^ax ai
  (tfa ^bx bi
    (tfa ^_ (subval ai ax bi bx)
      (subval
        ao[ ax ] (tcall ^x ai ao[ x ] a ax)
        bo[ bx ] (tcall ^x bi bo[ x ] b bx)))))

(coerce (ttfa ^x ao[ x ]) (ttfa ^x bo[ x ]) pf orig)
~~>
(ttfn ^x
  (ttcall ^x2 (subtype ao[ x2 ] bo[ x2 ]) pf x)
  (ttcall ^x2 ao[ x2 ] orig x))

(subtype (ttfa ^x ao[ x ]) (ttfa ^x bo[ x ]))
~~>
(ttfa ^x (subtype ao[ x ] bo[ x ]))

(subval (ttfa ^x ao[ x ]) a (ttfa ^x bo[ x ]) b)
~~>
(ttfa ^x
  (subval
    ao[ x ] (ttcall ^x2 ao[ x2 ] a x)
    bo[ x ] (ttcall ^x2 bo[ x2 ] b x)))

(coerce (sfa ^x ai ao[ x ]) (sfa ^x bi bo[ x ]) pf orig)
~~>
let
  convertypffntype4[ ax ][ bx ] = (subtype ao[ ax ] bo[ bx ])
  convertypffntype3[ ax ][ bx ] =
    (tfa ^_ (subval bi bx ai ax) convertypffntype4[ bx ][ ax ])
  convertypffntype2[ bx ] = (tfa ^ax ai convertypffntype3[ bx ][ ax ])
  convertypffntype1 = (tfa ^bx bi convertypffntype2[ bx ])
  convertxpf = (fst ^_ (subtype bi ai) convertypffntype1 pf)
  convertypf[ bx ][ ax ][ pf ] =
    (tcall ^_ (subval ai ax bi bx) convertypffntype4[ ax ][ bx ]
      (tcall ^bx2 bi convertypffntype3[ ax ][ bx2 ]
        (tcall ^ax2 ai convertypffntype2[ ax2 ][ bx2 ]
          (snd ^_ (subtype bi ai) convertypffntype1 pf)
          bx)
        ax)
      pf)
  ax = (fst ^x ai ao[ x ] orig)
  ay = (snd ^x ai ao[ x ] orig)
in
(sfn ^bx bi (coerce bi ai convertxpf x)
  (coerce ao[ ax ] bo[ bx ]
    convertypf[ ax ][ bx ][ (coherent convertxpf ax) ]
    ay))

(subtype (sfa ^x ai ao[ x ]) (sfa ^x bi bo[ x ]))
~~>
(sfa ^_ (subtype ai bi)
  (tfa ^ax ai
    (tfa ^bx bi
      (tfa ^_ (subval ai ax bi bx)
        (subtype ao[ ax ] bo[ bx ])))))

(subval (sfa ^x ai ao[ x ]) a (sfa ^x bi bo[ x ]) b)
~~>
(sfa ^_ (subval ai a bi b)
  (subval
    ao[ (fst ^x ai ao[ x ] a) ] (snd ^x ai ao[ x ] a)
    bo[ (fst ^x bi bo[ x ] b) ] (snd ^x bi bo[ x ] b)))



// ===== Action fragment =============================================


// == Grammar ==

// A root node:
MODULE ::= UserAction*

Fact ::=| UserVar "@!" UserAction
// NOTE: This is a user's knowledge that they have the choice to
// perform an action.
UserKnowledge ::=| "(" "can" UserAction ")"

// Only for depictions of external modules, not inference rules or
// actionable module code:
Term ::=| "<hiddenCode>"


// == Inference rules ==

// (none)



// ===== Knowledge query fragment ====================================
//
// Depends on the action fragment.

// NOTE: Right now, the (ttfa ...) type provides impredicative
// polymorphism, and it's difficult to add phantom types or other
// type-hiding tools without introducing the potential for
// nontermination. So we're going to drop (ttfa ...) and handle type
// parameters as a feature of exports and imports (knowledge queries),
// rather than as a feature of types.


// == Grammar ==

PolyTerm ::=| "(" "polytermunit" Term ")"
PolyTerm ::=| "(" "polytermforall" Arg PolyTerm ")"
PolyInst ::=| "(" "polyinstunit" ")"
PolyInst ::=| "(" "polyinstforall" Term PolyInst ")"
UserKnowledge ::=| "(" "polyistype" PolyTerm ")"
UserKnowledge ::=| "(" "polydescribes" PolyTerm PolyTerm ")"
UserKnowledge ::=| "(" "describesinst" PolyTerm PolyInst Term ")"
UserKnowledge ::=| "(" "describesquery" PolyTerm KnolQuery ")"
UserAction ::=| "(" "witheachtype" Arg UserAction ")"
UserAction ::=| "(" "witheachknol"
  Arg PolyTerm PolyInst Term KnolQuery UserAction ")"

// Only for inference rules, not code:
PolyTerm ::=| Word ("[" Term "]")*
PolyInst ::=| Word ("[" Term "]")*
KnolQuery ::=| Word ("[" Term "]")*

// Only for depictions of external modules, not inference rules or
// actionable module code:
Term ::=| "<hiddenCode>"


// == Inference rules ==

// Introduce (polytermunit ...) for types.
(istype a)
---
(polyistype (polytermunit a))

// Introduce (polytermunit ...) for values.
(describes aType a)
---
(polydescribes (polytermunit aType) (polytermunit a))

// Introduce (polytermforall ...) for types.
(istype x) |- (polyistype a[ x ])
---
(polyistype (polytermforall ^x a[ x ]))

// Introduce (polytermforall ...) for values.
(istype x) |- (polydescribes aType[ x ] a[ x ])
---
(polydescribes
  (polytermforall ^x aType[ x ]) (polytermforall ^x a[ x ]))

// Introduce (polyinstunit).
(istype x)
---
(describesinst (polytermunit x) (polyinstunit) r)

// Introduce (polyinstforall ...).
(istype x) |- (ispolytype nextType[ x ])
(istype xExample)
(describesinst nextType[ xExample ] nextInst r)
---
(describesinst (polytermforall ^x nextType[ x ])
  (polyinstforall xExample nextInst)
  r)

// Introduce (witheachtype ...).
(istype t) |- (can act[ t ])
---
(can (witheachtype ^t act[ t ]))

// Introduce (witheachknol ...).
(istype xType)
(describesinst polyType polyInst xType)
(describesquery polyType query)
(describes xType x) |- (can act[ x ])
---
(can (witheachknol ^x polyType polyInst xType query act[ x ]))



// ===== Local collaboration fragment ================================
//
// Depends on the deductive fragment and the action fragment.

// TODO: Make at least one cryptographic key syntax.


// == Grammar ==

UserKnowledge ::=| "(" "secret" Term ")"
UserKnowledge ::=| "(" "public" Key ")"
Key ::=| "(" "everyone" ")"
Key ::=| "(" "subkey" Key ExternallyVisibleWord ")"
UserAction ::=| "(" "withsecret" Arg Key UserAction ")"
// NOTE: In any place this grammar is used, an actual programming
// language implementation is very likely to use a different format.
// Sequences of ASCII letters aren't a very conscientious
// international standard.
ExternallyVisibleWord ::= "(" "sym" Word ")"

// Only for inference rules, not code:
Key ::=| "<language>"
Key ::=| KeyVar
KeyVar ::= Word | "myKey" | "yourKey" | "from" | "to" | "by" | "key"
ExternallyVisibleWord ::=| WordVar
WordVar ::= Word | "word"


// == Inference rules ==

// Introduce (everyone).
|-  // Tautology
---
(public (everyone))

// Introduce (subkey ...).
(public key)
---
(public (subkey key word))

// Introduce (withsecret ...).
(public key)
(secret x) |- (can act[ x ])
---
(can (withsecret x key act[ x ]))



// ===== Local collaborative value-level definition fragment =========
//
// Depends on the local collaboration fragment and the knowledge query
// fragment.


// == Grammar ==

UserAction ::=| "(" "define" Term Key Term Term ")"
KnolQuery ::=| "(" "defined" Key Term PolyTerm ")"


// == Inference rules ==

// Introduce (define ...).
(secret myKey)
(public yourKey)
(describes xType x)
---
(can (define myKey yourKey xType x))

// Introduce (defined ...).
you @ (public myKey)
you @ (secret yourKey)
you @ (polyistype xType)
---
you @ (describesquery xType (defined myKey yourKey xType))



// ===== Local collaborative phantom type fragment ===================
//
// Depends on the local collaboration fragment.
//
// TODO: If this wraps a (tfa ...), we can get nontermination! We
// should either stop using that impredicative type, abandon this
// fragment idea, or think outside the box some more.


// == Grammar ==

UserAction ::=| "(" "definewrapper" Term Term ")"
UserAction ::=| "(" "witheachwrapper" Arg Arg Term Term UserAction ")"
Term ::=| "(" "wrapper" Term ")"
// TODO: Figure out what else we might need in order to reason about
// equality of wrapped values.


// == Inference rules ==

// Introduce (wrapper ...).
(public by)
---
(istype (wrapper by))

// Introduce (definewrapper ...).
(secret by)
(istype innerType)
---
(can (definewrapper by innerType))

// Eliminate (definewrapper ...) and introduce (witheachwrapper ...).
me @! (definewrapper by innerType)
(secret by)
(istype innerType)
(describes (tfa ^_ innerType (wrapper by)) wrap),
  (describes (tfa ^_ (wrapper by) innerType) unwrap),
  |- (can act[ wrap ][ unwrap ])
---
(can
  (witheachwrapper ^wrap ^unwrap by innerType act[ wrap ][ unwrap ]))



// ===== Local collaborative extensible sum fragment =================
//
// Depends on the local collaboration fragment and the observational
// subtyping fragment.

// A certain user action can establish a new extensible sum type along
// with a policy on how that type can be extended. Another user can
// extend that sum with new cases, but only if they provide a way to
// preserve that policy, even in spite of others' independent ability
// to extend the sum.
//
// In a more user-friendly language, it may appear that several
// interdependent extensible sums and policies can be declared
// together in a bundle. However, that can probably be implemented on
// top of this single-sum, single-policy system.
//
// This system introduces a certain kind of infinity: Say one user
// starts a new extensible sum type (sumpart myKey). Another user
// extends it, but their extension family's index (i.e. newParts) is
// of type (sumpart myKey) itself, or of some related type, so now the
// inhabitants of (sumpart myKey) go into an infinite regress.
//
// TODO: See if that infinite regress leads to an embedding of
// inductive and/or coinductive definitions, or if it even leads to
// logical inconsistency.


// == Grammar ==

UserKnowledge ::=| "(" "extensible" Term ")"
UserAction ::=| "(" "startsum" Term Arg Term Term Arg Term ")"
UserAction ::=| "(" "witheachstartsum"
  Arg Arg Arg Term Arg Term Term Arg Term UserAction ")"
UserAction ::=| "(" "youcanextendsum" Term Key Arg Term ")"
UserAction ::=| "(" "extendsum" Key Term Term Arg Term ")"
UserAction ::=|
  "(" "witheachextendsum" Arg Arg Key Term Term UserAction ")"
Term ::=| "(" "sumpart" Key ")"
Term ::=| "(" "extendtype" Term Term ")"
Term ::=| "(" "stoe" Term Term ")"
Term ::=| "(" "etos" Term Term ")"
Term ::=| "(" "extend" Term Term ")"
// TODO: Figure out what else we might need in order to reason about
// equality of these values.


// == Inference rules ==

// Introduce (sumpart ...).
(public by)
---
(istype (sumpart by))

// Introduce (startsum ...).
(secret myKey)
(istype seedParts)
(istype x1) |- (istype accum[ x1 ])
(istype e1), (extensible e1)
  |- (describes accum[ (extendtype seedParts e1) ]
       seedImplementation[ e1 ])
---
(can
  (startsum myKey ^x accum[ x ] seedParts ^e seedImplementation[ e ]))

// Eliminate (startsum ...) and introduce (witheachstartsum ...).
me @!
  (startsum myKey ^x accum[ x ] seedParts ^e seedImplementation[ e ])
(describes (tfa ^_ seedParts (sumpart myKey)) sumExt),
  (describes (tfa ^_ (sumpart myKey) (maybe seedParts)) sumExtElim),
  (describes accum[ (sumpart mykey) ] sumOut)
  |- (can act[ sumExt ][ sumExtElim ][ sumOut ])
---
(can
  (witheachstartsum ^sumExt ^sumExtElim ^sumOut
    myKey ^x accum[ x ] seedParts ^e seedImplementation[ e ]
    act[ sumExt ][ sumExtElim ][ sumOut ]))

// Eliminate (startsum ...) and introduce (youcanextendsum ...).
//
// TODO: See if we actually need to share accum[ x ] itself or if we
// can share less information while still making it just as possible
// to formulate an extension.
//
// TODO: See if we need to send an abstracted version of accum[ x ] in
// order to make certain kinds of extension invariants possible to
// enforce.
//
me @!
  (startsum myKey ^x accum[ x ] seedParts ^e seedImplementation[ e ])
(public yourKey)
---
(can (youcanextendsum myKey yourKey ^x accum[ x ]))

// Eliminate (youcanextendsum ...) and introduce (extendsum ...).
//
// TODO: The point of incorporating (sumpart myKey) is so we can take
// full advantage of preexisting definitions related to this sum when
// making an extension. See if this approach fully accomplishes this
// goal, and see if its circularity somehow leads to inconsistency.
//
// NOTE: We're having (subtype ...) indicate a proof that there's
// exactly one way to coerce, so that it stays proof-irrelevant.
// However, we're using (subval ...) to indicate that a value of one
// type supports no more observations than another value of another
// type. If we let (subtype ...) be computationally relevant,
// extend[ e ] could just be a (subtype ...) proof.
//
me @! (youcanextendsum myKey yourKey x1 accum[ x1 ])
you @ (public myKey)
you @ (secret yourKey)
you @ (istype myParts)
(you @ (istype x2)) |- (you @ (istype accum[ x2 ]))
(you @ (istype e1)), (you @ (extensible e1)) |-
  (you @
    let
      xParts = (extendtype (sumpart myKey) e1)
      yParts = (extendtype myParts xParts)
    in
    (describes
      (tfa ^x accum[ xParts ]
        (sfa ^y accum[ yParts ]
          (subval accum[ xParts ] x accum[ yParts ] y)))
      extend[ e1 ]))
---
you @ (can (extendsum myKey yourKey myParts ^e extend[ e ]))

// Eliminate (extendsum ...) and introduce (witheachextendsum ...).
you @! (extendsum myKey yourKey myParts ^e extend[ e ])
you @ (public myKey)
you @ (secret yourKey)
you @ (istype myParts)
(you @ (describes (tfa ^_ myParts (sumpart myKey)) sumExt)),
  (you @
    (describes (tfa ^_ (sumpart myKey) (maybe myParts)) sumExtElim))
  |- (you @ (can act[ sumExt ][ sumExtElim ]))
---
you @
  (can
    (witheachextendsum ^sumExt ^sumExtElim myKey yourKey myParts
      act[ sumExt ][ sumExtElim ]))

// Introduce #Extend, #stoe, #etos, and #extend.
(istype myParts)
(extensible e)
---
(istype (extendtype myParts e))
(extensible (extendtype myParts e))
(describes (tfa ^_ (either myParts e) (extendtype myParts e))
  (stoe myParts e))
(describes (tfa ^_ (extendtype myParts e) (either myParts e))
  (etos myParts e))
(describes
  (tfa ^x e
    (sfa ^y (extendtype myParts e)
      (subval e x (extendtype myParts e) y)))
  (extend myParts e))

// TODO: See if (extend ...) is enough to actually prove the things we
// need to prove for (extendsum ...). We might not have transitivity
// of (subval ...) yet, or something.



// TODO: Consider adding another approach to extensible sum types.
//
// Term ::=| "(" "knolset" Term ")"
// Term ::=| "(" "mysterytype" ")"
// Term ::=| "(" "mystery" Term Term Term ")"
// Term ::=| "(" "dispatcher" Term Term ")"
// UserAction ::=| "(" "extenddispatcher" Term Key Term Term Term ")"
//
// If some people do
// (extenddispatcher from to inputType resultType func), with each
// "func" of type (tfa ^_ inputType (k resultType)), then a person
// with access to "to" can use those methods via
// (dispatcher to resultType), which has type
// (tfa ^_ (mysterytype) (knolset resultType)). Values of type
// (mysterytype), created using (mystery from inputType inputVal),
// will dispatch to the method defined on the same "from" key and type
// that created them.
//
// It's not clear yet what we should be able to do with values of type
// (knolset ...).



// ===== Partiality monad fragment ===================================
//
// Depends on the deductive fragment.
//
// TODO: Come up with a better fragment name.


// == Grammar ==

Term ::=| "(" "partialtype" Term ")"
// TODO: Make sure all syntaxes that begin with "z" are hidden from
// language users.
Term ::=| "(" "zunitpartial" Term Term ")"
Term ::=| "(" "zbindpartial" Term Term Term Term ")"
Term ::=| "(" "zfixpartial" Term Term ")"
// TODO: Figure out what else we might need in order to reason about
// equality of these values.


// == Inference rules ==

// Introduce (partialtype ...).
(istype a)
---
(istype (partialtype a))

// Introduce (zunitpartial ...).
(describes a x)
---
(describes (partialtype a) (zunitpartial a x))

// Introduce (zbindpartial ...).
(describes (partialtype aType) thunkA)
(describes (tfa ^_ aType (partialtype bType)) aToThunkB)
---
(describes (partialtype bType)
  (zbindpartial aType bType thunkA aToThunkB))

// Introduce (zfixpartial ...).
(describes (tfa ^_ (partialtype a) (partialtype a)) thunkToThunk)
---
(describes (partialtype a) (zfixpartial a thunkToThunk))


// == Built-in module exports ==

unitpartial : (ttfa ^a (tfa ^_ a (partialtype a)))

bindpartial :
  (ttfa ^a
    (ttfa ^b
      (tfa ^_ (partialtype a)
        (tfa ^_ (tfa ^_ a (partialtype b)) (partialtype b)))))

fixpartial :
  (ttfa ^a
    (tfa ^_ (tfa ^_ (partialtype a) (partialtype a))
      (partialtype a)))



// ===== Imperative partial computation fragment =====================
//
// Depends on the partiality monad fragment.
//
// This takes primary inspiration from [1]. The original formulation
// of this idea is in [2], whose authors continued their analysis in
// [3].
//
// [1] "A new paradigm for component-based development,"
//     Johan G. Granstrom, 2012.
// [2] "Interactive Programs in Dependent Type Theory,"
//     Peter Hancock and Anton Setzer, 2000.
// [3] "Interactive Programs and Weakly Final Coalgebras in Dependent
//     Type Theory (Extended Version),"
//     Anton Setzer and Peter Hancock, 2005.
//
// This representation of imperative computation has some accidental
// complexity, a meaningful use case we don't necessarily intend to
// support: It's possible for the execution harness to manipulate
// continuations and thereby perform branching, reentrant, and/or
// early termination effects as in Haskell Monads. If we had linear
// types, we could restrict this. The approach in "A new paradigm..."
// might mitigate this in practice since a "world map" doesn't seem
// like it would introduce these features in the target world unless
// they already exist in the source world.

// NOTE: Occurrences of "impartial" here are short for "imperative
// partial," and they distinguish this kind of imperative computation
// from at least two other possibilities: One where the computation
// must terminate after a finite number of commands, and one where
// each stage of computation must terminate in full termination or a
// command, but where infinite regresses of commands are permitted.
//
// TODO: See if there's a better term than "impartial."


// == Grammar ==

Term ::=| "(" "impartialtype" Arg Term Term Term ")"
Term ::=| "(" "unitimpartial" Arg Term Term Term ")"
Term ::=| "(" "invkimpartial" Arg Term Term Term Term ")"
// TODO: Figure out what else we might need in order to reason about
// equality of these values.


// == Inference rules ==

// Introduce (impartialtype ...).
(istype commandType)
(describes commandType cmd) |- (istype responseType[ cmd ])
(istype terminationType)
---
(istype
  (impartialtype ^cmd commandType responseType[ cmd ]
    terminationType))

// Introduce (unitimpartial ...).
(istype commandType)
(describes commandType cmd) |- (istype responseType[ cmd ])
(describes terminationType result)
---
(describes
  (impartialtype ^cmd commandType responseType[ cmd ] terminationType)
  (unitimpartial ^cmd commandType responseType[ cmd ] result))

// Introduce (invkimpartial ...).
(istype commandType)
(describes commandType cmd) |- (istype responseType[ cmd ])
(describes terminationType result)
(describes
  (sfa ^cmd commandType
    (tfa ^_ responseType[ cmd ]
      (partialtype
        (impartialtype ^cmd commandType responseType[ cmd ]
          terminationType))))
  pairOfCommandAndCallback)
---
(describes
  (impartialtype ^cmd commandType responseType[ cmd ] terminationType)
  (invkimpartial ^cmd commandType responseType[ cmd ] terminationType
    pairOfCommandAndCallback))



// ===== Statically generated dynamic token fragment =================
//
// Depends on the deductive fragment and the action fragment.


// == Grammar ==

Term ::=| "(" "tokentype" ")"
UserAction ::=| "(" "withtoken" Arg Term UserAction ")"
// TODO: Make sure all syntaxes that begin with "z" are hidden from
// language users.
Term ::=| "(" "ztokenequals" Term Term ")"
// TODO: Figure out what else we might need in order to reason about
// equality of these values.


// == Inference rules ==

// Introduce (tokentype ...).
|-  // Tautology
---
(istype (tokentype))

// Introduce (withtoken ...).
(private by)
(describes (tokentype) t) |- (can act[ t ])
---
(can (withtoken ^t by act[ t ]))

// Introduce (ztokenequals ...).
(describes (tokentype) a)
(describes (tokentype) b)
---
(describes (bool) (ztokenequals a b))


// == Built-in module exports ==

tokenequals : (tfa ^_ (tokentype) (tfa ^_ (tokentype) (bool)))



// ===== Kitchen sink "un"-type fragment =============================
//
// Depends on the imperative partial computation fragment and the
// statically generated dynamic token fragment.
//
// TODO: Come up with a better fragment name.

// TODO: Use the phantom type fragment or extensible sum fragment for
// this. Note that we can't just handle all types at once: If the type
// (tfa _ (sink) (sink)) can be contained in a sink, then we can
// formulate the Y combinator and we lose the "total" property of our
// total functions. Moreover, not all types can necessarily be
// programmatically compared for observational equality (in order to
// check whether the sink destruction type matches the construction
// type), and not all types will necessarily be able to survive past
// compile time.


// == Grammar ==

Term ::=| "(" "sink" ")"
// TODO: Make sure all syntaxes that begin with "z" are hidden from
// language users.
Term ::=| "(" "ztokentosink" Term ")"
Term ::=| "(" "zsinktotoken" Term ")"
Term ::=| "(" "zpfntosink" Term ")"
Term ::=| "(" "zsinktopfn" Term ")"
Term ::=| "(" "zipfntosink" Term ")"
Term ::=| "(" "zsinktoipfn" Term ")"
// TODO: Figure out what else we might need in order to reason about
// equality of these values.


// == Inference rules ==

// Introduce (ztokentosink ...).
(istype (tokentype) x)
---
(istype (sink) (ztokentosink x))

// Introduce (zsinktotoken ...).
(istype (sink) x)
---
(istype (maybe (tokentype)) (zsinktotoken x))

// Introduce (zpfntosink ...).
(istype (tfa ^_ (sink) (partialtype (sink))) x)
---
(istype (sink) (zpfntosink x))

// Introduce (zsinktopfn ...).
(istype (sink) x)
---
(istype (maybe (tfa ^_ (sink) (partialtype (sink)))) (zsinktopfn x))

// Introduce (zipfntosink ...).
(istype
  (tfa ^_ (sink)
    (partialtype (impartialtype ^_ (sink) (sink) (sink))))
  x)
---
(istype (sink) (zipfntosink x))

// Introduce (zsinktoipfn ...).
(istype (sink) x)
---
(istype
  (maybe
    (tfa ^_ (sink)
      (partialtype (impartialtype ^_ (sink) (sink) (sink)))))
  (zsinktoipfn x))


// == Built-in module exports ==

tokentosink : (tfa ^_ (tokentype) (sink))
sinktotoken : (tfa ^_ (sink) (maybe (tokentype)))

// TODO: See if we need this.
// NOTE: "pfn" = "partial function"
pfntosink : (tfa ^_ (tfa ^_ (sink) (partialtype (sink))) (sink))
sinktopfn :
  (tfa ^_ (sink) (maybe (tfa ^_ (sink) (partialtype (sink)))))

// NOTE: "ipfn" = "imperative partial function"
ipfntosink :
  (tfa ^_
    (tfa ^_ (sink)
      (partialtype (impartialtype ^_ (sink) (sink) (sink))))
    (sink))
sinktoipfn :
  (tfa ^_ (sink)
    (maybe
      (tfa ^_ (sink)
        (partialtype (impartialtype ^_ (sink) (sink) (sink))))))



// ===== Example built-in module: Natural numbers ====================

(withsecret nat (subkey <language> (sym nat))
  (define (subkey <language> (sym natZero)) (everyone)
    (polytermunit (wrappertype nat))
    (polytermunit <hiddenCode>)))
(withsecret nat (subkey <language> (sym nat))
  (define (subkey <language> (sym natSucc)) (everyone)
    (polytermunit (tfa ^_ (wrappertype nat) (wrappertype nat)))
    (polytermunit <hiddenCode>)))
(withsecret nat (subkey <language> (sym nat))
  (define (subkey <language> (sym natElim)) (everyone)
    (polytermforall ^a
      (polytermunit
        (tfa ^_ (wrappertype nat)
          (tfa ^_ a (tfa ^_ (tfa ^_ a a) a)))))
    (polytermforall ^a (polytermunit <hiddenCode>))))
